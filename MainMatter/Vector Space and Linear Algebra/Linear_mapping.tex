\chapter{Linear Mapping and Matrix}
By definition, for a vector sapce $V$, we know $(V,+)$ is an Abelian group. It's natural to consider the group homomorphisms and isomorphisms on vector spaces.
We'll see linear mapping as a group homomorphism and discover some more fine properties in this chapter.

\section{Linear Mapping}
\subsection{the Definitions}
\begin{definition}[Linear Mapping]
    For a function $\varphi$ from the vector space $V$ to the vector space $W$, if the following statements hold, we call it a linear mapping\footnote{One may ask if such a mapping exists. 
    The answer is yes as there exists a unique linear mapping that takes the basis of $V$ to the basis of $W$, see \cite[p.~54]{Axler_2024} for proof of this proposition.}.
    \begin{itemize}
        \item $\varphi(v_1+v_2) = \varphi(v_1) +\varphi(v_2),\forall v_1,v_2 \in V.$
        \item $\varphi(\lambda v) =\lambda \varphi(v),\forall \lambda \in \mathcal{F}.$
    \end{itemize}
    We denote the set of all linear mappings from $V$ to $W$ as $\mathcal{L}(V,W)$.
\end{definition}

It's clear that a linear mapping is indeed a homomorphism, so we can easily translate some of the definitions and propositions from group homomorphisms to linear mappings.
\begin{definition}[Kernel]
    The kernel of a linear mapping $\varphi \in \mathcal{L}(V,W)$ is defined as $$\operatorname{Ker} \varphi = \{v \in V : \varphi(v) = 0\}$$
\end{definition}

\begin{proposition}
    Suppose $\varphi \in \mathcal{L}(V,W)$, then the following holds:
    \begin{itemize}
        \item $\varphi(0) = 0$
        \item $\varphi$ is injective $\iff \operatorname{Ker} (\varphi)$ is trivial. 
    \end{itemize}
\end{proposition}

We can also define the operations on $\mathcal{L}(V,W)$.
\begin{definition}[Operations on $\mathcal{L}(V,W)$]
    Let $\mathcal{L}(V,W)$ be the set of all linear mappings from $V$ to $W$, we have 3 operations on it:
    \begin{description}
        \item[Addition] $\forall \varphi, \varpi \in \mathcal{L}(V,W), (\varphi+ \varpi)(v) = \varphi(v) + \varpi(v)$
        \item[Scalar Multiplication] $\forall \lambda \in \mathcal{F}, (\lambda \varphi)(v) = \lambda (\varphi(v))$
        \item[Product (Combination)]  $\forall \varphi, \varpi \in \mathcal{L}(V,W), (\varphi \varpi)(v) = \varphi\circ \varpi(v)$
    \end{description}
    \,Then $\mathcal{L}(V,W)$ is a vector space.
\end{definition}

\subsection{Isomorphic Linear Mapping}
Before we start to deal with isomorphisms, we first dig deeper into the linear mappings of finite-dimensional vector spaces.
\begin{theorem}[Fundamental Theorem of Linear Mappings] \namedlabel{thm: Fundamental_Linear_Mapping}{the fundamental theorem of linear mappings}
    Suppose $\varphi \in \mathcal{L}(V,W)$, then $$\dim V = \dim \operatorname{Im}\varphi + \dim \operatorname{Ker} \varphi$$
\end{theorem}
\begin{proof}
    Let $u_1,\cdots,u_n$ be a basis of $\operatorname{Ker} \varphi$. By \lemmaref{lem: steinitz}, we can extend them as $u_1,\cdots,u_n, v_1,\cdots, v_m$ so that
    it becomes a basis of $V$. We close the proof by showing $\varphi(v_1) ,\cdots,\varphi(v_n)$ is a basis of $\operatorname{Im}\varphi$.

    We first show that $\varphi(v_1) ,\cdots,\varphi(v_n)$ spans $\operatorname{Im} \varphi$. Notice that $\forall v \in V$, we can rewrite it as $a_1 u_1+\cdots+a_m u_m +b_1 v_1 +\cdots + b_n v_n = v$. Thus
    $$\varphi(v) = b_1 \varphi(v_1) +\cdots +b_n \varphi(v_n)$$
    \,implying $\varphi(v) \in \operatorname{span}(\varphi(v_1) ,\cdots,\varphi(v_n)).$

    Now we show the linear independence\footnote{From this part we can also show that an isomorphic linear mapping maps a linearly independent list to a linearly independent list.}. Suppose $c_1 v_1+\cdots+c_nv_n=0$, then $\varphi(c_1 v_1+\cdots+c_nv_n)=0$, meaning $c_1 v_1+\cdots+c_nv_n \in \operatorname{Ker} \varphi.$
    We can rewrite it with the linear combination of $u_1,\cdots,u_m$, say $c_1 v_1+\cdots+c_nv_n = d_1 u_1 +\cdots +d_m u_m$. Since $u_1,\cdots,u_n, v_1,\cdots, v_m$ is linearly independent, all $c$'s and $d$'s are zero.
\end{proof}

\begin{corollary} \label{cor: mapping}
    Suppose $V$ and $W$ are vector spaces. If $\dim V < \dim W$, $\varphi \in \mathcal{L}(V,W)$ is NOT surjective. If $\dim V > \dim W$, $\varphi \in \mathcal{L}(V,W)$ is NOT injective
\end{corollary}

With these results, we can depict an isomorphism with ease.
\begin{definition}[Isomorphic Linear Mapping]
    If a linear mapping is bijective, we say it's isomorphic.
\end{definition}

We know by \corref{cor: mapping} that a necessary condition for a linear mapping to be isomorphic is that the finite-dimensional vector spaces have the same dimension.
\begin{corollary}
    Suppose $\varphi \in \mathcal{L}(V,W)$ with $\dim V = \dim W$, Then
    $$\varphi \text{ is isomorphic} \iff \operatorname{Ker} \varphi \text{ is trivial} \iff \operatorname{Im} \varphi = W \iff \varphi \text{ is invertible}$$
\end{corollary}
\begin{proof}
    Use \thmref{thm: Fundamental_Linear_Mapping}, we have 
    $$\varphi \text{ is surjective} \iff \operatorname{Im} \varphi = W \iff \dim \operatorname{Ker} \varphi = 0 \iff \varphi \text{ is injective}$$
\end{proof}

If there exists an isomorphism from $V$ to $W$, we say $V$ and $W$ are isomorphic.
\begin{theorem} \label{thm: isomorphic_spaces}
    $V$ and $W$ are isomorphic $\iff \dim V = \dim W$. 
\end{theorem}

\section{Matrix}
\subsection{From Vector to Coordinate}
From \thmref{thm: isomorphic_spaces}, we know that $V$, whose dimension is $n$, and $\mathcal{F}^{n}$ is isomorphic. That is to say there exists a bijection
$\mathcal{M}:V\to \mathcal{F}^{n}$. For a basis of $V$, denoted by $v_1,\cdots, v_n$, we construct the isomorphism as follows: 
$$v_i \mapsto (\underbrace{0,\cdots, 1,\cdots, 0}_{\text{the } i\text{th slot equals to 1}}).$$
Then, for $v \in V$, we can write it as $v = a_1 v_1 +\cdots +a_n v_n$ and $$\mathcal{M}(v) = a_1 \mathcal{M}(v_1) +\cdots +a_n \mathcal{M}(v_n)$$
\,this leads us to the definition of coordinate.
\begin{definition}[Coordinate]
    Suppose for $v \in V$, we have $v = a_1 v_1 +\cdots +a_n v_n$, then its coordinate is defined as 
    $$\mathcal{M}(v) = (a_1, a_2,\cdots, a_n).$$
\end{definition}

\subsection{From Linear Mapping to Matrix}
Note that we can also write $(f_1, \cdots, f_n)$ in a column, that is 
$$\begin{pmatrix}
    f_1  \\ \vdots  \\ f_n 
\end{pmatrix}$$
\,or simply denote it by $(f_1,\cdots, f_n)^{t}$. Wether to write a vector in $\mathcal{F}^n$ in a row or in a column is basically for simplicity of the notation.
We'll see the benefits when presenting the $m$-direct product of $\mathcal{F}^n$. Suppose $\mathbf{f}_1,\cdots \mathbf{f}_m \in \mathcal{F}^n$, elements of the direct product $\mathcal{F}^{n,m}$
can be written as $(\mathbf{f}_1,\cdots \mathbf{f}_m)$ and we drop the brackets of $\mathbf{f}$'s, that is 
$$\begin{pmatrix}
f_{11}  &\cdots  & f_{1m}\\
\vdots  & \ddots & \vdots\\
f_{n1} &\cdots & f_{nm}
\end{pmatrix}.$$

A similar result of the previous example is that $\mathcal{F}^{n,m}$ is a vector space with dimension $nm$. 

Notice that $\dim \mathcal{L}(V,W) = nm$ if $\dim V = m$ and $\dim W = n$. So it's natural to construct an isomorphism to give a specific representation of linear mappings.
Suppose $\varphi \in \mathcal{L}(V,W)$ with $\dim V = n$ and $\dim W = m$. Let $v_1,\cdots,v_m$ be a basis of $V$ and $w_1,\cdots, w_n$ be a basis of $W$.
We try to calculate $\mathcal{M}( \varphi(v_i))$ so that we can know the coordinate of any vectors in $\varphi(V)$ by linear combination. Suppose $ \varphi(v_i) = a_{1i} w_1+ a_{2i}w_2 +\cdots +a_{ni} w_n$, then 
$$\mathcal{M}( \varphi(v_i)) = (a_{1i} , a_{2i} ,\cdots ,a_{ni})^{t}.$$ 
Thus, we can present $\varphi$ by 
$$\begin{pmatrix}
a_{11}  &\cdots  & a_{1m}\\
\vdots  & \ddots & \vdots\\
a_{n1} &\cdots & a_{nm}
\end{pmatrix}.$$

\begin{definition}[Matrix]
    Suppose $\varphi \in \mathcal{L}(V,W)$ and the basis of $V$ and $W$ are $(v_1,\cdots,v_m)$ and $(w_1,\cdots, w_n)$ respectively, then the matrix of $\varphi$ with respect to the basis $(v_1,\cdots,v_m)$ and $(w_1,\cdots, w_n)$ is defined as
    $$\mathcal{M}(\varphi,(v_1,\cdots,v_m),(w_1,\cdots, w_n)) \footnote{Simply use the notation $\mathcal{M}(\varphi)$ when the basis is clear from the context.} = \begin{pNiceMatrix}[first-row,first-col]
    & v_1 & \cdots & v_k & \cdots & v_m \\
    w_1 & & & a_{1k} & & \\
    \Vdots & & & \Vdots & & \\
    w_n & & & a_{nk} & & 
    \end{pNiceMatrix}$$
    where $\{a_{ij}\}_{(i,j) = (1,1)}^{(n,m)}$ satisfy $ \varphi(v_k) = a_{1k} w_1+ a_{2k}w_2 +\cdots +a_{nk} w_n$ for $k = 1,\dots,m$. We denote the set of matrix with $n$ rows and $m$ columns as $\mathcal{F}^{n,m}$.
\end{definition}

\subsection{Operations of Matrix}
As mentioned before, a matrix is basically a linear mapping. In this way we define the operations of matrixes analogous to the operations of linear mappings.
\begin{description}
    \item[Addition] Suppose $\varphi,\varpi \in \mathcal{L}(V, W)$ and we have $\varphi \left(v_{k}\right)=a_{1 k} w_{1}+\cdots+a_{n k} w_{n}$ and $\varpi\left(v_{k}\right)=b_{1 k} w_{1}+\cdots+b_{n k} w_{n}$.
    $$(\varphi+\varpi)\left(v_{k}\right)=\varphi\left(v_{k}\right)+\varpi \left(v_{k}\right)=\left(a_{1 k}+b_{1 k}\right) w_{1}+\cdots+\left(a_{n k}+b_{n k}\right) w_{n}$$ 
    
    \item[Scalar Multiplication] Suppose $\varphi \in \mathcal{L}(V, W)$ and $\varphi\left(v_{k}\right)=a_{1 k} w_{1}+\cdots+a_{n k} w_{n}$. For $\lambda \in \mathbb{F}$,
    $$(\lambda \varphi)\left(v_{k}\right)=\lambda\left(\varphi\left(v_{k}\right)\right)=\lambda a_{1 k} w_{1}+\cdots+\lambda a_{n k} w_{n}$$
    
    \item[Product (Composition)] Suppose $\varphi \in \mathcal{L}(V, W)$ and $\psi \in \mathcal{L}(W, U)$, with $\varphi\left(v_{k}\right)=a_{1 k} w_{1}+\cdots+a_{n k} w_{n}$ and $\psi\left(w_{k}\right)=b_{1 k} u_{1}+\cdots+b_{p k} u_{p}$. Then the composition $\psi \circ \varphi$ satisfies:
    $$\begin{aligned}
    (\psi \circ \varphi)\left(v_{k}\right)=\psi\left(\varphi\left(v_{k}\right)\right) & =a_{1 k} \psi\left(w_{1}\right)+\cdots+a_{n k} \psi\left(w_{n}\right) \\
    & =a_{1 k} \sum_{i=1}^{p} b_{i 1} u_{i}+\cdots+a_{n k} \sum_{i=1}^{p} b_{i n} u_{i} \\
    & =\left(\sum_{j=1}^{n} b_{1 j} a_{j k}\right) u_{1}+\cdots+\left(\sum_{j=1}^{n} b_{p j} a_{j k}\right) u_{p}
    \end{aligned}$$
\end{description}

This leads us to the following definitions.
\begin{definition}[Operations of Matrix]
    In the space of matrices, we can define the following operations:
    \begin{itemize}
        \item \textbf{Addition:} For matrices $A = \mathcal{M}(\varphi)$ and $B = \mathcal{M}(\varpi)$ in $\mathcal{F}^{n,m}$ (with respect to the same bases),
        $$\mathcal{M}(\varphi+\varpi) = \mathcal{M}(\varphi) + \mathcal{M}(\varpi),$$
        that is,
        $$\begin{aligned}
        \begin{pNiceMatrix}[first-row,first-col]
        & v_1 & \cdots & v_k & \cdots & v_m \\
        w_1 & & & a_{1k} & & \\
        \Vdots & & & \Vdots & & \\
        w_n & & & a_{nk} & & 
        \end{pNiceMatrix}
        &+
        \begin{pNiceMatrix}[first-row,first-col]
        & v_1 & \cdots & v_k & \cdots & v_m \\
        w_1 & & & b_{1k} & & \\
        \Vdots & & & \Vdots & & \\
        w_n & & & b_{nk} & & 
        \end{pNiceMatrix} \\
        &=
        \begin{pNiceMatrix}[first-row,first-col]
        & v_1 & \cdots & v_k & \cdots & v_m \\
        w_1 & & & a_{1k}+b_{1k} & & \\
        \Vdots & & & \Vdots & & \\
        w_n & & & a_{nk}+b_{nk} & & 
        \end{pNiceMatrix}
        \end{aligned}$$
        
        \item \textbf{Scalar Multiplication:} For a matrix $A = \mathcal{M}(\varphi)$ in $\mathcal{F}^{n,m}$ and a scalar $\lambda \in \mathbb{F}$,
        $$\mathcal{M}(\lambda\varphi) = \lambda\mathcal{M}(\varphi),$$
        that is,
        $$\lambda
        \begin{pNiceMatrix}[first-row,first-col]
        & v_1 & \cdots & v_k & \cdots & v_m \\
        w_1 & & & a_{1k} & & \\
        \Vdots & & & \Vdots & & \\
        w_n & & & a_{nk} & & 
        \end{pNiceMatrix}
        =
        \begin{pNiceMatrix}[first-row,first-col]
        & v_1 & \cdots & v_k & \cdots & v_m \\
        w_1 & & & \lambda a_{1k} & & \\
        \Vdots & & & \Vdots & & \\
        w_n & & & \lambda a_{nk} & & 
        \end{pNiceMatrix}$$
        
        \item \textbf{Multiplication (Composition):} For matrices $A = \mathcal{M}(\varphi) \in \mathcal{F}^{n,m}$ (with respect to bases of $V$ and $W$) and $B = \mathcal{M}(\psi) \in \mathcal{F}^{p,n}$ (with respect to bases of $W$ and $U$),
        $$\mathcal{M}(\psi \circ \varphi) = \mathcal{M}(\psi)\mathcal{M}(\varphi) = BA,$$
        that is,
        $$\begin{aligned}
        \begin{pNiceMatrix}[first-row,first-col]
        & w_1 & \cdots & w_k & \cdots & w_n \\
        u_1 & & & b_{1k} & & \\
        \Vdots & & & \Vdots & & \\
        u_p & & & b_{pk} & & 
        \end{pNiceMatrix} \cdot
        &\begin{pNiceMatrix}[first-row,last-col]
        v_1 & \cdots & v_k & \cdots & v_m & \\
        & & a_{1k} & & & w_1 \\
        & & \Vdots & & & \Vdots \\
        & & a_{nk} & & & w_n 
        \end{pNiceMatrix} \\
        &=
        \begin{pNiceMatrix}[first-row,first-col]
        & v_1 & \cdots & v_k & \cdots & v_m \\
        u_1 & & & \sum_{j=1}^{n} b_{1j} a_{jk} & & \\
        \Vdots & & & \Vdots & & \\
        u_p & & & \sum_{j=1}^{n} b_{pj} a_{jk} & & 
        \end{pNiceMatrix}
        \end{aligned}$$
        Note that the product matrix $BA$ is in $\mathcal{F}^{p,m}$, corresponding to the linear mapping $\psi \circ \varphi: V \to U$.
    \end{itemize}
\end{definition}
